{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9707861,"sourceType":"datasetVersion","datasetId":5937508}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom osgeo import gdal\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:55:46.725502Z","iopub.execute_input":"2025-03-18T17:55:46.725832Z","iopub.status.idle":"2025-03-18T17:55:47.866380Z","shell.execute_reply.started":"2025-03-18T17:55:46.725806Z","shell.execute_reply":"2025-03-18T17:55:47.865297Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## **Extract AWS data**\n* Extract all values\n* Filter always-null pixels","metadata":{}},{"cell_type":"code","source":"import os\nfrom datetime import datetime, timedelta\n\ndef extract_timestamp_from_filename(filename):\n    \"\"\"\n    Tr√≠ch xu·∫•t timestamp t·ª´ t√™n file theo ƒë·ªãnh d·∫°ng 'AWS_YYYYMMDDHHMMSS.tif'\n    \"\"\"\n    try:\n        base_name = filename.split('.')[0]  # B·ªè ph·∫ßn m·ªü r·ªông .tif\n        parts = base_name.split('_')\n        if len(parts) < 2:\n            return None\n        timestamp_str = parts[-1]  # Ph·∫ßn YYYYMMDDHHMMSS\n        timestamp = datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S\")\n        return timestamp\n    except Exception:\n        return None\n\ndef check_missing_hours(root_dir):\n    \"\"\"\n    Ki·ªÉm tra xem trong th√°ng 4 v√† th√°ng 10 c·ªßa nƒÉm 2019 & 2020 c√≥ thi·∫øu b·∫•t k·ª≥ gi·ªù n√†o kh√¥ng.\n    Tr·∫£ v·ªÅ t·∫≠p h·ª£p (set) c√°c timestamp b·ªã thi·∫øu.\n    \"\"\"\n    missing_hours = set()\n\n    for year in ['2019', '2020']:\n        for month in ['04', '10']:  # Ch·ªâ ki·ªÉm tra th√°ng 4 v√† th√°ng 10\n            month_path = os.path.join(root_dir, year, month)\n            if not os.path.isdir(month_path):\n                print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c th√°ng: {year}/{month}\")\n                continue\n\n            expected_hours_per_day = {datetime(int(year), int(month), day, hour) \n                                      for day in range(1, 31)  # Th√°ng 4 v√† th√°ng 10 c√≥ 30 ng√†y\n                                      for hour in range(24)}\n            available_timestamps = set()\n\n            for day in sorted(os.listdir(month_path)):\n                day_path = os.path.join(month_path, day)\n                if not os.path.isdir(day_path):\n                    continue\n\n                for file in sorted(os.listdir(day_path)):\n                    if file.endswith(\".tif\"):\n                        timestamp = extract_timestamp_from_filename(file)\n                        if timestamp:\n                            available_timestamps.add(timestamp)\n\n            # X√°c ƒë·ªãnh timestamp b·ªã thi·∫øu v√† th√™m v√†o t·∫≠p `missing_hours`\n            missing_hours.update(expected_hours_per_day - available_timestamps)\n\n    if missing_hours:\n        print(f\"‚ö†Ô∏è T·ªïng s·ªë timestamp b·ªã thi·∫øu: {len(missing_hours)}\")\n    else:\n        print(\"‚úÖ D·ªØ li·ªáu ƒë·∫ßy ƒë·ªß, kh√¥ng c√≥ gi·ªù n√†o b·ªã thi·∫øu!\")\n\n    return missing_hours if missing_hours else None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:55:47.867674Z","iopub.execute_input":"2025-03-18T17:55:47.868183Z","iopub.status.idle":"2025-03-18T17:55:47.879118Z","shell.execute_reply.started":"2025-03-18T17:55:47.868153Z","shell.execute_reply":"2025-03-18T17:55:47.877814Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom osgeo import gdal\nfrom datetime import datetime, timedelta\n\ndef extract_data(root_dir, option=1, coordinates=None):\n    \"\"\"\n    Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c file GeoTIFF trong th∆∞ m·ª•c root_dir v√† b·ªï sung d·ªØ li·ªáu b·ªã thi·∫øu.\n    \n    - root_dir: ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c g·ªëc\n    - option: \n        + 1 - Tr·∫£ v·ªÅ to√†n b·ªô d·ªØ li·ªáu\n        + 2 - Ch·ªâ l·∫•y d·ªØ li·ªáu ·ªü c√°c t·ªça ƒë·ªô c·ª• th·ªÉ (row, col) trong t·∫≠p `coordinates`\n    - coordinates: set ch·ª©a c√°c t·ªça ƒë·ªô (row, col) n·∫øu option = 2\n    \n    Returns:\n    - dict ch·ª©a DataFrame c·ªßa t·ª´ng th√°ng, v·ªõi key l√† \"YYYY-MM\".\n    \"\"\"\n    \n    monthly_data = {}\n    param_name = root_dir.split('/')[-1]  # T·ª± ƒë·ªông l·∫•y t√™n bi·∫øn kh√≠ t∆∞·ª£ng\n\n    for year in ['2019', '2020']:\n        year_path = os.path.join(root_dir, year)\n        if not os.path.isdir(year_path):\n            continue\n\n        for month in sorted(os.listdir(year_path)):\n            month_path = os.path.join(year_path, month)\n            if not os.path.isdir(month_path):\n                continue\n\n            available_timestamps = set()\n            pixel_values = {}  # L∆∞u d·ªØ li·ªáu c·ªßa t·ª´ng pixel\n\n            for day in tqdm(sorted(os.listdir(month_path)), desc=f\"ƒêang x·ª≠ l√Ω {year}/{month}\"):\n                day_path = os.path.join(month_path, day)\n                if not os.path.isdir(day_path):\n                    continue\n\n                for file in sorted(os.listdir(day_path)):\n                    if not file.endswith(\".tif\"):\n                        continue\n                    file_path = os.path.join(day_path, file)\n\n                    dataset = gdal.Open(file_path)\n                    if dataset is None:\n                        print(f\"‚ö†Ô∏è Kh√¥ng m·ªü ƒë∆∞·ª£c file: {file_path}\")\n                        continue\n\n                    band = dataset.GetRasterBand(1)\n                    data = band.ReadAsArray()\n\n                    base = file.split('.')[0]\n                    parts = base.split('_')\n                    if len(parts) >= 2:\n                        dt_str = parts[-1]\n                        dt = datetime.strptime(dt_str, \"%Y%m%d%H%M%S\")\n                    else:\n                        dt = None\n                    \n                    available_timestamps.add(dt)\n\n                    rows, cols = data.shape\n                    row_idx, col_idx = np.indices((rows, cols))\n\n                    # √Åp d·ª•ng ƒëi·ªÅu ki·ªán l·ªçc d·ªØ li·ªáu h·ª£p l·ªá\n                    valid_mask = np.ones_like(data, dtype=bool)\n\n                    # N·∫øu option == 2, ch·ªâ gi·ªØ l·∫°i c√°c t·ªça ƒë·ªô c√≥ trong `coordinates`\n                    if option == 2 and coordinates:\n                        coord_mask = np.vectorize(lambda r, c: (r, c) in coordinates)(row_idx, col_idx)\n                        valid_mask &= coord_mask\n\n                    values = data[valid_mask]\n                    row_idx = row_idx[valid_mask]\n                    col_idx = col_idx[valid_mask]\n\n                    for r, c, v in zip(row_idx, col_idx, values):\n                        if (r, c) not in pixel_values:\n                            pixel_values[(r, c)] = {}\n                        pixel_values[(r, c)][dt] = v\n\n            # T·∫°o danh s√°ch timestamp ƒë·∫ßy ƒë·ªß cho th√°ng ƒë√≥\n            start_date = datetime(int(year), int(month), 1, 0, 0, 0)\n            end_date = datetime(int(year), int(month), 30, 23, 0, 0)\n            all_timestamps = {start_date + timedelta(hours=i) for i in range((end_date - start_date).days * 24 + 24)}\n\n            missing_timestamps = all_timestamps - available_timestamps\n\n            # ƒêi·ªÅn NaN v√†o c√°c timestamp b·ªã thi·∫øu\n            for pixel, values in pixel_values.items():\n                for ts in missing_timestamps:\n                    values[ts] = np.nan\n\n            # Chuy·ªÉn d·ªØ li·ªáu th√†nh DataFrame\n            data_list = []\n            for (r, c), values in pixel_values.items():\n                for ts, v in values.items():\n                    data_list.append([ts, r, c, v])\n\n            month_key = f\"{year}-{month}\"\n            df = pd.DataFrame(data_list, columns=[\"datetime\", \"row\", \"col\", param_name])\n            df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n            df[\"row\"] = df[\"row\"].astype(int)\n            df[\"col\"] = df[\"col\"].astype(int)\n            df[param_name] = df[param_name].astype(float)\n\n            monthly_data[month_key] = df\n\n    return monthly_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:55:47.881548Z","iopub.execute_input":"2025-03-18T17:55:47.881888Z","iopub.status.idle":"2025-03-18T17:55:47.912029Z","shell.execute_reply.started":"2025-03-18T17:55:47.881858Z","shell.execute_reply":"2025-03-18T17:55:47.910784Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Ki·ªÉm tra s·ªë l∆∞·ª£ng ·∫£nh t·ª´ng th√°ng xem c√≥ gi·ªëng nhau**","metadata":{}},{"cell_type":"code","source":"import os\n\ndef count_tif_files(root_dir):\n    \"\"\"\n    ƒê·∫øm s·ªë l∆∞·ª£ng file .tif trong t·ª´ng th∆∞ m·ª•c th√°ng c·ªßa root_dir.\n    \n    Returns:\n    - Dictionary { \"YYYY-MM\": s·ªë l∆∞·ª£ng file .tif }\n    \"\"\"\n    file_counts = {}\n\n    for year in ['2019', '2020']:\n        year_path = os.path.join(root_dir, year)\n        if not os.path.isdir(year_path):\n            continue\n\n        for month in sorted(os.listdir(year_path)):\n            month_path = os.path.join(year_path, month)\n            if not os.path.isdir(month_path):\n                continue\n\n            tif_count = sum(\n                1 for day in os.listdir(month_path)\n                if os.path.isdir(os.path.join(month_path, day))\n                for file in os.listdir(os.path.join(month_path, day))\n                if file.endswith(\".tif\")\n            )\n\n            file_counts[f\"{year}-{month}\"] = tif_count\n\n    return file_counts\n\n\n# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c g·ªëc ch·ª©a d·ªØ li·ªáu\nroot_directory = \"/kaggle/input/rainfall-forecast/DATA_SV/Precipitation/AWS\"\n\n# G·ªçi h√†m v√† in k·∫øt qu·∫£\ntif_file_counts = count_tif_files(root_directory)\nfor month, count in tif_file_counts.items():\n    print(f\"{month}: {count} files\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:55:47.913835Z","iopub.execute_input":"2025-03-18T17:55:47.914209Z","iopub.status.idle":"2025-03-18T17:55:49.924025Z","shell.execute_reply.started":"2025-03-18T17:55:47.914171Z","shell.execute_reply":"2025-03-18T17:55:49.922922Z"}},"outputs":[{"name":"stdout","text":"2019-04: 720 files\n2019-10: 627 files\n2020-04: 718 files\n2020-10: 742 files\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Kh√¥ng gi·ªëng nhau => c√≥ c√°c m·ªëc th·ªùi gian b·ªã thi·∫øu tuy nhi√™n s·ªë l∆∞·ª£ng kh√¥ng ƒë√°ng k·ªÉ\n","metadata":{}},{"cell_type":"code","source":"# AWS raw data\naws_raw_data = extract_data('/kaggle/input/rainfall-forecast/DATA_SV/Precipitation/AWS')\n\naws_raw_data.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:55:49.925211Z","iopub.execute_input":"2025-03-18T17:55:49.925568Z","iopub.status.idle":"2025-03-18T18:04:33.620356Z","shell.execute_reply.started":"2025-03-18T17:55:49.925540Z","shell.execute_reply":"2025-03-18T18:04:33.618937Z"}},"outputs":[{"name":"stderr","text":"ƒêang x·ª≠ l√Ω 2019/04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:27<00:00,  1.09it/s]\nƒêang x·ª≠ l√Ω 2019/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:23<00:00,  1.33it/s]\nƒêang x·ª≠ l√Ω 2020/04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:26<00:00,  1.12it/s]\nƒêang x·ª≠ l√Ω 2020/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:27<00:00,  1.14it/s]\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"dict_keys(['2019-04', '2019-10', '2020-04', '2020-10'])"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def get_valid_pixels(result):\n    \"\"\"\n    X√°c ƒë·ªãnh t·∫≠p h·ª£p c√°c pixel (row, col) c√≥ √≠t nh·∫•t m·ªôt gi√° tr·ªã h·ª£p l·ªá trong b·∫•t k·ª≥ th√°ng n√†o.\n    \n    Parameters:\n    - result (dict): Dictionary ch·ª©a c√°c DataFrame c·ªßa t·ª´ng th√°ng (output t·ª´ `extract_data`).\n    \n    Returns:\n    - set: T·∫≠p h·ª£p t·ªça ƒë·ªô (row, col) h·ª£p l·ªá.\n    \"\"\"\n    if not result:\n        return set()\n\n    # L·∫•y t√™n bi·∫øn kh√≠ t∆∞·ª£ng t·ª´ m·ªôt DataFrame b·∫•t k·ª≥\n    sample_df = next(iter(result.values()))\n    param_name = sample_df.columns[-1]  # C·ªôt cu·ªëi c√πng l√† gi√° tr·ªã kh√≠ t∆∞·ª£ng (U250, AWS, ...)\n\n    valid_pixels = set()\n\n    # Duy·ªát qua t·ª´ng DataFrame ƒë·ªÉ t√¨m c√°c t·ªça ƒë·ªô c√≥ √≠t nh·∫•t m·ªôt gi√° tr·ªã h·ª£p l·ªá\n    for df in tqdm(result.values()):\n        for row, col, value in zip(df[\"row\"], df[\"col\"], df[param_name]):\n            if value != -np.inf and not pd.isna(value):  # N·∫øu gi√° tr·ªã kh√¥ng ph·∫£i -inf, th√™m v√†o t·∫≠p h·ª£p\n                valid_pixels.add((row, col))\n\n    return valid_pixels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T18:04:33.621766Z","iopub.execute_input":"2025-03-18T18:04:33.622075Z","iopub.status.idle":"2025-03-18T18:04:33.629501Z","shell.execute_reply.started":"2025-03-18T18:04:33.622050Z","shell.execute_reply":"2025-03-18T18:04:33.628409Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"aws_valid_pixels = get_valid_pixels(aws_raw_data)\n\nlen(aws_valid_pixels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T18:04:33.630686Z","iopub.execute_input":"2025-03-18T18:04:33.631075Z","iopub.status.idle":"2025-03-18T18:04:59.557491Z","shell.execute_reply.started":"2025-03-18T18:04:33.631030Z","shell.execute_reply":"2025-03-18T18:04:59.556485Z"}},"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:25<00:00,  6.47s/it]\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"334"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"filtered_aws_data = extract_data('/kaggle/input/rainfall-forecast/DATA_SV/Precipitation/AWS', option = 2, coordinates=aws_valid_pixels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T18:04:59.560016Z","iopub.execute_input":"2025-03-18T18:04:59.560365Z","iopub.status.idle":"2025-03-18T18:05:27.853040Z","shell.execute_reply.started":"2025-03-18T18:04:59.560335Z","shell.execute_reply":"2025-03-18T18:05:27.851883Z"}},"outputs":[{"name":"stderr","text":"ƒêang x·ª≠ l√Ω 2019/04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:05<00:00,  5.02it/s]\nƒêang x·ª≠ l√Ω 2019/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:05<00:00,  5.70it/s]\nƒêang x·ª≠ l√Ω 2020/04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:05<00:00,  5.02it/s]\nƒêang x·ª≠ l√Ω 2020/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:05<00:00,  5.74it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for key, value in filtered_aws_data.items():\n    print(key)\n    print(value.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T18:05:27.854158Z","iopub.execute_input":"2025-03-18T18:05:27.854503Z","iopub.status.idle":"2025-03-18T18:05:27.913495Z","shell.execute_reply.started":"2025-03-18T18:05:27.854476Z","shell.execute_reply":"2025-03-18T18:05:27.912376Z"}},"outputs":[{"name":"stdout","text":"2019-04\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 240480 entries, 0 to 240479\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype         \n---  ------    --------------   -----         \n 0   datetime  240480 non-null  datetime64[ns]\n 1   row       240480 non-null  int64         \n 2   col       240480 non-null  int64         \n 3   AWS       240480 non-null  float64       \ndtypes: datetime64[ns](1), float64(1), int64(2)\nmemory usage: 7.3 MB\nNone\n2019-10\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 248496 entries, 0 to 248495\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype         \n---  ------    --------------   -----         \n 0   datetime  248496 non-null  datetime64[ns]\n 1   row       248496 non-null  int64         \n 2   col       248496 non-null  int64         \n 3   AWS       209418 non-null  float64       \ndtypes: datetime64[ns](1), float64(1), int64(2)\nmemory usage: 7.6 MB\nNone\n2020-04\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 240480 entries, 0 to 240479\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype         \n---  ------    --------------   -----         \n 0   datetime  240480 non-null  datetime64[ns]\n 1   row       240480 non-null  int64         \n 2   col       240480 non-null  int64         \n 3   AWS       239812 non-null  float64       \ndtypes: datetime64[ns](1), float64(1), int64(2)\nmemory usage: 7.3 MB\nNone\n2020-10\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 248496 entries, 0 to 248495\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype         \n---  ------    --------------   -----         \n 0   datetime  248496 non-null  datetime64[ns]\n 1   row       248496 non-null  int64         \n 2   col       248496 non-null  int64         \n 3   AWS       247828 non-null  float64       \ndtypes: datetime64[ns](1), float64(1), int64(2)\nmemory usage: 7.6 MB\nNone\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Extract ERA5 data\n* Extract ERA5 features corresponding to AWS pixels\n* Merge into 1 dataframe and save","metadata":{}},{"cell_type":"code","source":"import os\n\n# Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu ERA5\nera5_root = \"/kaggle/input/rainfall-forecast/DATA_SV/ERA5\"\n\n# T·∫°o m·ªôt dictionary ƒë·ªÉ l∆∞u DataFrame c·ªßa t·ª´ng th∆∞ m·ª•c con trong ERA5\nera5_data_dict = {}\n\n# Duy·ªát qua t·∫•t c·∫£ c√°c th∆∞ m·ª•c con c·ªßa ERA5\nfor subdir in sorted(os.listdir(era5_root)):\n    subdir_path = os.path.join(era5_root, subdir)\n    \n    if os.path.isdir(subdir_path):  # Ch·ªâ x·ª≠ l√Ω n·∫øu l√† th∆∞ m·ª•c\n        print(f\"üìÇ ƒêang x·ª≠ l√Ω folder con: {subdir}\")\n        era5_data_dict[subdir] = extract_data(subdir_path, option=2, coordinates=aws_valid_pixels)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir = \"/kaggle/working/merged_data\"\n\n# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\nos.makedirs(output_dir, exist_ok=True)\n\n# üü¢ G·ªôp v√† l∆∞u t·ª´ng th√°ng ri√™ng bi·ªát\nfor month in filtered_aws_data.keys():\n    df = filtered_aws_data[month]  # L·∫•y DataFrame AWS c·ªßa th√°ng ƒë√≥\n\n    # Merge v·ªõi t·ª´ng tr∆∞·ªùng c·ªßa ERA5 n·∫øu c√≥ d·ªØ li·ªáu c√πng th√°ng\n    for var_name, era5_dict in era5_data_dict.items():\n        if month in era5_dict:\n            df = df.merge(era5_dict[month], on=[\"datetime\", \"row\", \"col\"], how=\"left\", suffixes=(\"\", f\"_{var_name}\"))\n\n    # üìù L∆∞u DataFrame t·ª´ng th√°ng\n    output_path = os.path.join(output_dir, f\"merged_{month}.csv\")\n    df.to_csv(output_path, index=False)\n    print(f\"‚úÖ ƒê√£ l∆∞u {output_path}\")\n\nprint(\"üéØ Ho√†n t·∫•t qu√° tr√¨nh g·ªôp v√† l∆∞u!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T18:27:07.448877Z","iopub.execute_input":"2025-03-18T18:27:07.449264Z","iopub.status.idle":"2025-03-18T18:27:47.109423Z","shell.execute_reply.started":"2025-03-18T18:27:07.449215Z","shell.execute_reply":"2025-03-18T18:27:47.108299Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ƒê√£ l∆∞u /kaggle/working/merged_data/merged_2019-04.csv\n‚úÖ ƒê√£ l∆∞u /kaggle/working/merged_data/merged_2019-10.csv\n‚úÖ ƒê√£ l∆∞u /kaggle/working/merged_data/merged_2020-04.csv\n‚úÖ ƒê√£ l∆∞u /kaggle/working/merged_data/merged_2020-10.csv\nüéØ Ho√†n t·∫•t qu√° tr√¨nh g·ªôp v√† l∆∞u!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}